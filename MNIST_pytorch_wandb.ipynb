{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_pytorch_wandb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjTlczuFe/hOUZu8PKUt3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/debugNNwithWandB/blob/master/MNIST_pytorch_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HESv1l--3AAa",
        "colab_type": "code",
        "outputId": "86270867-710a-49e5-cd82-af75e7d292bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 25.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 10.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 962kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 53.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25h  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg0iv_RPT3YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcjcQ3-UH2H",
        "colab_type": "code",
        "outputId": "d9aeb8b1-dc5e-4b58-9fef-7927b30e09fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 69f60a7711ce6b8bbae91ac6d15e45d6b1f1430e\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFZ81yY3Rfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiEHlMTh4ecC",
        "colab_type": "code",
        "outputId": "c3184d3b-778e-4c63-d634-0065fe1edcf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtM4FMPP3imH",
        "colab_type": "code",
        "outputId": "14db2f45-fe78-4c60-c365-f32c6d2c110b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8764061.51it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 130381.41it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2146658.06it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 50403.98it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33T4NzgLjNlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUOU5phlFoZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Conv 1st Block\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Cv0XLX54Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, steps_per_epoch=20):\n",
        "  # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "  model.train()\n",
        "  train_total = 0\n",
        "  train_correct = 0\n",
        "\n",
        "  # We loop over the data iterator, and feed the inputs to the network and adjust the weights.\n",
        "  for batch_idx, (data, target) in enumerate(train_loader, start=0):\n",
        "    if batch_idx > steps_per_epoch:\n",
        "      break\n",
        "    # Load the input features and labels from the training dataset\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    \n",
        "    # Reset the gradients to 0 for all learnable weight parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass: Pass image data from training dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "    output = model(data)\n",
        "    \n",
        "    # Define our loss function, and compute the loss\n",
        "    loss = F.nll_loss(output, target)\n",
        "\n",
        "    scores, predictions = torch.max(output.data, 1)\n",
        "    train_total += target.size(0)\n",
        "    train_correct += int(sum(predictions == target))\n",
        "            \n",
        "    # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the neural network weights\n",
        "    optimizer.step()\n",
        "\n",
        "  acc = round((train_correct / train_total) * 100, 2)\n",
        "  print('Epoch [{}], Loss: {}, Accuracy: {}'.format(epoch, loss.item(), acc))\n",
        "  wandb.log({'Train Loss': loss.item(), 'Train Accuracy': acc})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcCrrPJ65p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader, classes):\n",
        "    # Switch model to evaluation mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "\n",
        "    example_images = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            # Load the input features and labels from the test dataset\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            # Make predictions: Pass image data from test dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "            output = model(data)\n",
        "            \n",
        "            # Compute the loss sum up batch loss\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            # print('[INFO] Test loss: ', test_loss)\n",
        "\n",
        "            # Get the index of the max log-probability\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            \n",
        "            # WandB – Log images in your test dataset automatically, along with predicted and true labels by passing pytorch tensors with image data into wandb.Image\n",
        "            # example_images.append(wandb.Image(\n",
        "            #     data[0], caption=\"Pred: {} Truth: {}\".format(classes[pred[0].item()], classes[target[0]])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYSE0Psw38w0",
        "colab_type": "code",
        "outputId": "7c524593-436a-4b2d-ad33-f7c5e99e32bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "net = Net().to(device)\n",
        "print(net)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJMOZ1Qt69f3",
        "colab_type": "code",
        "outputId": "8d68f2d4-7616-4c61-ba82-3e4da866f7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "wandb.init(project='pytorchw_b')\n",
        "wandb.watch(net, log='all')\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(net, device, trainloader, optimizer, epoch)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ayush-thakur/pytorchw_b\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/pytorchw_b</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ayush-thakur/pytorchw_b/runs/kcerbkio\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/pytorchw_b/runs/kcerbkio</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], Loss: 0.49014565348625183, Accuracy: 61.24\n",
            "Epoch [1], Loss: 0.5604876279830933, Accuracy: 87.35\n",
            "Epoch [2], Loss: 0.3222809433937073, Accuracy: 92.34\n",
            "Epoch [3], Loss: 0.2817479372024536, Accuracy: 93.01\n",
            "Epoch [4], Loss: 0.1235792487859726, Accuracy: 95.39\n",
            "Epoch [5], Loss: 0.06383541226387024, Accuracy: 95.98\n",
            "Epoch [6], Loss: 0.17832785844802856, Accuracy: 95.39\n",
            "Epoch [7], Loss: 0.0948452353477478, Accuracy: 96.5\n",
            "Epoch [8], Loss: 0.05486568808555603, Accuracy: 96.65\n",
            "Epoch [9], Loss: 0.23081035912036896, Accuracy: 95.98\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imbae7Ut-Yy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}