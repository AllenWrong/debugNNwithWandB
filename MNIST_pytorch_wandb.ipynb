{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_pytorch_wandb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0Cr7TnBkYH3GCz/WZ5lDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/debugNNwithWandB/blob/master/MNIST_pytorch_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HESv1l--3AAa",
        "colab_type": "code",
        "outputId": "ea33672e-df70-4816-dbef-20e340120d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 32.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 3.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 962kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 2.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 14.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 61.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 14.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[?25h  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg0iv_RPT3YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcjcQ3-UH2H",
        "colab_type": "code",
        "outputId": "7eb05494-b295-4514-90e1-5548a46e333f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 69f60a7711ce6b8bbae91ac6d15e45d6b1f1430e\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFZ81yY3Rfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiEHlMTh4ecC",
        "colab_type": "code",
        "outputId": "3e2f9c5c-e1f3-42ad-daf9-54a14afaf6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtM4FMPP3imH",
        "colab_type": "code",
        "outputId": "a18965af-fe60-4e2e-a694-89ae8d541b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 28545996.19it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 473780.39it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 146564.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7853165.74it/s]                          \n",
            "8192it [00:00, 196880.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33T4NzgLjNlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUOU5phlFoZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Conv 1st Block\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Cv0XLX54Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, steps_per_epoch=20):\n",
        "  # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "  model.train()\n",
        "  train_total = 0\n",
        "  train_correct = 0\n",
        "\n",
        "  # We loop over the data iterator, and feed the inputs to the network and adjust the weights.\n",
        "  for batch_idx, (data, target) in enumerate(train_loader, start=0):\n",
        "    if batch_idx > steps_per_epoch:\n",
        "      break\n",
        "    # Load the input features and labels from the training dataset\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    \n",
        "    # Reset the gradients to 0 for all learnable weight parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass: Pass image data from training dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "    output = model(data)\n",
        "    \n",
        "    # Define our loss function, and compute the loss\n",
        "    loss = F.nll_loss(output, target)\n",
        "\n",
        "    scores, predictions = torch.max(output.data, 1)\n",
        "    train_total += target.size(0)\n",
        "    train_correct += int(sum(predictions == target))\n",
        "            \n",
        "    # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the neural network weights\n",
        "    optimizer.step()\n",
        "\n",
        "  acc = round((train_correct / train_total) * 100, 2)\n",
        "  print('Epoch [{}], Loss: {}, Accuracy: {}'.format(epoch, loss.item(), acc), end='')\n",
        "  wandb.log({'Train Loss': loss.item(), 'Train Accuracy': acc})\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcCrrPJ65p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader, classes):\n",
        "  # Switch model to evaluation mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  test_total = 0\n",
        "  test_correct = 0\n",
        "\n",
        "  example_images = []\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          # Load the input features and labels from the test dataset\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          \n",
        "          # Make predictions: Pass image data from test dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "          output = model(data)\n",
        "          \n",
        "          # Compute the loss sum up batch loss\n",
        "          test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "          \n",
        "          scores, predictions = torch.max(output.data, 1)\n",
        "          test_total += target.size(0)\n",
        "          test_correct += int(sum(predictions == target))\n",
        "          \n",
        "          # WandB – Log images in your test dataset automatically, along with predicted and true labels by passing pytorch tensors with image data into wandb.Image\n",
        "          # example_images.append(wandb.Image(\n",
        "          #     data[0], caption=\"Pred: {} Truth: {}\".format(classes[pred[0].item()], classes[target[0]])))\n",
        "  acc = round((test_correct / test_total) * 100, 2)\n",
        "  print(' Test_loss: {}, Test_accuracy: {}'.format(test_loss/test_total, acc))\n",
        "  wandb.log({'Test Loss': test_loss, 'Test Accuracy': acc})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYSE0Psw38w0",
        "colab_type": "code",
        "outputId": "6c7d7b9b-ebce-4719-fd7e-ef0ce39a3d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "net = Net().to(device)\n",
        "print(net)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJMOZ1Qt69f3",
        "colab_type": "code",
        "outputId": "28a3651d-89ea-4a0c-eed0-306d49920bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "wandb.init(project='pytorchw_b')\n",
        "wandb.watch(net, log='all')\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(net, device, trainloader, optimizer, epoch)\n",
        "  test(net, device, testloader, classes)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ayush-thakur/pytorchw_b\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/pytorchw_b</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ayush-thakur/pytorchw_b/runs/6obadxu6\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/pytorchw_b/runs/6obadxu6</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], Loss: 0.3299920856952667, Accuracy: 67.63 Test Loss: 0.5349190994262696, Test Accuracy: 83.77\n",
            "Epoch [1], Loss: 0.406034380197525, Accuracy: 85.94 Test Loss: 0.28489854464530945, Test Accuracy: 92.25\n",
            "Epoch [2], Loss: 0.27714571356773376, Accuracy: 92.11 Test Loss: 0.24341122879981994, Test Accuracy: 92.89\n",
            "Epoch [3], Loss: 0.2721991539001465, Accuracy: 94.72 Test Loss: 0.1725113487958908, Test Accuracy: 95.02\n",
            "Epoch [4], Loss: 0.12737764418125153, Accuracy: 95.24 Test Loss: 0.1528898442029953, Test Accuracy: 95.66\n",
            "Epoch [5], Loss: 0.299007385969162, Accuracy: 96.21 Test Loss: 0.11600023686885834, Test Accuracy: 96.49\n",
            "Epoch [6], Loss: 0.44035637378692627, Accuracy: 95.98 Test Loss: 0.10958966701030731, Test Accuracy: 96.79\n",
            "Epoch [7], Loss: 0.10584037005901337, Accuracy: 95.76 Test Loss: 0.1116433946609497, Test Accuracy: 96.72\n",
            "Epoch [8], Loss: 0.13834434747695923, Accuracy: 96.95 Test Loss: 0.10117772641181946, Test Accuracy: 96.72\n",
            "Epoch [9], Loss: 0.09104746580123901, Accuracy: 97.77 Test Loss: 0.08724266715049743, Test Accuracy: 97.37\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y534xBF1m70M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}