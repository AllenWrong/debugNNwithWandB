{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_pytorch_wandb_Overfit_Small",
      "provenance": [],
      "authorship_tag": "ABX9TyP4p/+xIdyxvJ6V6bT3Fofv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/debugNNwithWandB/blob/master/MNIST_pytorch_wandb_Overfit_Small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJrTcams9S6G",
        "colab_type": "text"
      },
      "source": [
        "## Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HESv1l--3AAa",
        "colab_type": "code",
        "outputId": "a1f2f6a9-4dbb-4be1-ca03-4a59bdc6f50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 23.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 14.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 55.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 13.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 15.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.7MB/s \n",
            "\u001b[?25h  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg0iv_RPT3YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcjcQ3-UH2H",
        "colab_type": "code",
        "outputId": "1d60a5b5-9710-4d97-e491-b73bee665e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 69f60a7711ce6b8bbae91ac6d15e45d6b1f1430e\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFZ81yY3Rfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtakKUgw9Ype",
        "colab_type": "text"
      },
      "source": [
        "#### For GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiEHlMTh4ecC",
        "colab_type": "code",
        "outputId": "57bc4b80-a69b-4732-ba56-75346d13483e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIxBcFVg9clX",
        "colab_type": "text"
      },
      "source": [
        "## MNIST Hand written Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtM4FMPP3imH",
        "colab_type": "code",
        "outputId": "8dc3fb1b-7a03-4b6d-f184-528d4a304dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:02, 3380381.50it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 49386.55it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:02, 817525.30it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 18514.62it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33T4NzgLjNlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHUm-bi79yfr",
        "colab_type": "text"
      },
      "source": [
        "## Small Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI2iHfA86RmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_small, y_small = iter(trainloader).next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUEXlZ9B8oJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b79ad60-0f58-4d79-e8f8-b99f2b1aa431"
      },
      "source": [
        "x_small.shape, y_small.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8luRi8q9pyh",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3rki8u__TU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, bias=False)\n",
        "\n",
        "        self.fc1 = nn.Linear(9216, 128, bias=False)\n",
        "        self.fc2 = nn.Linear(128, 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Conv 1st Block\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x) \n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMdRyuPV96yk",
        "colab_type": "text"
      },
      "source": [
        "#### Train loop modified for one batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Cv0XLX54Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, data, target, optimizer, epoch, steps_per_epoch=20):\n",
        "  # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "  model.train()\n",
        "  train_total = 0\n",
        "  train_correct = 0\n",
        "\n",
        "  # Load the input features and labels from the training dataset\n",
        "  data, target = data.to(device), target.to(device)\n",
        "  \n",
        "  # Reset the gradients to 0 for all learnable weight parameters\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # Forward pass: Pass image data from training dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "  output = model(data)\n",
        "  \n",
        "  # Define our loss function, and compute the loss\n",
        "  loss = F.nll_loss(output, target)\n",
        "\n",
        "  scores, predictions = torch.max(output.data, 1)\n",
        "  train_total += target.size(0)\n",
        "  train_correct += int(sum(predictions == target))\n",
        "          \n",
        "  # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
        "  loss.backward()\n",
        "  \n",
        "  # Update the neural network weights\n",
        "  optimizer.step()\n",
        "\n",
        "  acc = round((train_correct / train_total) * 100, 2)\n",
        "  print('Epoch [{}], Loss: {}, Accuracy: {}, '.format(epoch, loss.item(), acc))\n",
        "  wandb.log({'Train Loss': loss.item(), 'Train Accuracy': acc})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCv0BZIUDd81",
        "colab_type": "code",
        "outputId": "07de0cbe-7cde-43cd-e32a-c89f897272f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "net = Net().to(device)\n",
        "print(net)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=False)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVGiu_9hJv9_",
        "colab_type": "code",
        "outputId": "1d28c89f-4fe8-422b-c5f2-21e204c92050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "wandb.init(project='overfitsmall')\n",
        "wandb.watch(net, log='all')\n",
        "\n",
        "for epoch in range(5):\n",
        "  train(net, device, x_small, y_small, optimizer, epoch)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ayush-thakur/overfitsmall\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/overfitsmall</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ayush-thakur/overfitsmall/runs/fyhe4cjp\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/overfitsmall/runs/fyhe4cjp</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], Loss: 2.295197010040283, Accuracy: 17.19, \n",
            "Epoch [1], Loss: 1.8784966468811035, Accuracy: 23.44, \n",
            "Epoch [2], Loss: 1.437056541442871, Accuracy: 54.69, \n",
            "Epoch [3], Loss: 0.9664705991744995, Accuracy: 89.06, \n",
            "Epoch [4], Loss: 0.6278926134109497, Accuracy: 92.19, \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgDAlzv7KSew",
        "colab_type": "text"
      },
      "source": [
        "> The model quickly fitted to the small data. Our model is good to go. We can now train on full dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpQA6RLL9voj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}