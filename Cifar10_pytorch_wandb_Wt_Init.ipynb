{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10_pytorch_wandb_Wt_Init",
      "provenance": [],
      "authorship_tag": "ABX9TyM21XawNyJDO7GJstiDn0g+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/debugNNwithWandB/blob/master/Cifar10_pytorch_wandb_Wt_Init.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJrTcams9S6G",
        "colab_type": "text"
      },
      "source": [
        "## Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HESv1l--3AAa",
        "colab_type": "code",
        "outputId": "f85d2c1d-40ac-4c31-9e58-85c6b75fbc3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 30.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 19.1MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 18.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 19.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 16.7MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 18.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 17.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 16.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 16.6MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 962kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 16.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 45.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 10.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg0iv_RPT3YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcjcQ3-UH2H",
        "colab_type": "code",
        "outputId": "de05d3f6-39e9-452a-90e1-f71547d359fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 69f60a7711ce6b8bbae91ac6d15e45d6b1f1430e\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFZ81yY3Rfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtakKUgw9Ype",
        "colab_type": "text"
      },
      "source": [
        "#### For GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiEHlMTh4ecC",
        "colab_type": "code",
        "outputId": "7c1f6120-cd21-47ea-9a08-325f4d7cfd0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIxBcFVg9clX",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtM4FMPP3imH",
        "colab_type": "code",
        "outputId": "e1222dd5-2236-4a40-8464-1a1e7dfde798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 168402944/170498071 [00:14<00:00, 14038255.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E6tH8wrn2_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "4881bc3b-d3a0-4e77-dfdc-bb92ba92cef2"
      },
      "source": [
        "trainset"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2ce56135-b4e3-43be-8915-f1b62d764fbf",
        "id": "Wpspb4owhqsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "iter(trainloader).next()[0][0].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8luRi8q9pyh",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph_iU0V5jGUR",
        "colab_type": "code",
        "outputId": "a95bbc6d-7128-41de-e802-695b98d76f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBNVNJcLjNoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79CJt73EjTLX",
        "colab_type": "code",
        "outputId": "0b12f9c4-35ed-4b3e-e69a-17ba81b6d5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='valid')(inputs)\n",
        "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='valid')(inputs)\n",
        "x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='valid')(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='valid')(x)\n",
        "x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs, x)\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 942,986\n",
            "Trainable params: 942,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3rki8u__TU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, 1)\n",
        "\n",
        "        self.pool1 = torch.nn.MaxPool2d(2)\n",
        "        self.pool2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.fc1 = nn.Linear(1600, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Conv 1st Block\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Cv0XLX54Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, steps_per_epoch):\n",
        "  # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "  model.train()\n",
        "  train_total = 0\n",
        "  train_correct = 0\n",
        "\n",
        "  # We loop over the data iterator, and feed the inputs to the network and adjust the weights.\n",
        "  for batch_idx, (data, target) in enumerate(train_loader, start=0):\n",
        "    if batch_idx > steps_per_epoch:\n",
        "      break\n",
        "    # Load the input features and labels from the training dataset\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    \n",
        "    # Reset the gradients to 0 for all learnable weight parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass: Pass image data from training dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "    output = model(data)\n",
        "    \n",
        "    # Define our loss function, and compute the loss\n",
        "    loss = F.nll_loss(output, target)\n",
        "\n",
        "    scores, predictions = torch.max(output.data, 1)\n",
        "    train_total += target.size(0)\n",
        "    train_correct += int(sum(predictions == target))\n",
        "            \n",
        "    # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the neural network weights\n",
        "    optimizer.step()\n",
        "\n",
        "  acc = round((train_correct / train_total) * 100, 2)\n",
        "  print('Epoch [{}], Loss: {}, Accuracy: {}, '.format(epoch, loss.item(), acc), end='')\n",
        "  wandb.log({'Train Loss': loss.item(), 'Train Accuracy': acc})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcCrrPJ65p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader, classes):\n",
        "  # Switch model to evaluation mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0\n",
        "  test_total = 0\n",
        "  test_correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          # Load the input features and labels from the test dataset\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          \n",
        "          # Make predictions: Pass image data from test dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "          output = model(data)\n",
        "          \n",
        "          # Compute the loss sum up batch loss\n",
        "          test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "          \n",
        "          scores, predictions = torch.max(output.data, 1)\n",
        "          test_total += target.size(0)\n",
        "          test_correct += int(sum(predictions == target))\n",
        "          \n",
        "  acc = round((test_correct / test_total) * 100, 2)\n",
        "  print(' Test_loss: {}, Test_accuracy: {}'.format(test_loss/test_total, acc))\n",
        "  wandb.log({'Test Loss': test_loss/test_total, 'Test Accuracy': acc})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZvNwsrk_xFa",
        "colab_type": "text"
      },
      "source": [
        "## Let's train it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYSE0Psw38w0",
        "colab_type": "code",
        "outputId": "a4032136-373b-44fe-c971-9d8dac7977f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "net = Net().to(device)\n",
        "print(net)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1600, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJMOZ1Qt69f3",
        "colab_type": "code",
        "outputId": "dee260c6-5f69-473a-c358-0e3aaba7d92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "wandb.init(project='wtinit')\n",
        "wandb.watch(net, log='all')\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(net, device, trainloader, optimizer, epoch, steps_per_epoch=50000//32)\n",
        "  test(net, device, testloader, classes)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ayush-thakur/wtinit\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/wtinit</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ayush-thakur/wtinit/runs/tbw3n3x8\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/wtinit/runs/tbw3n3x8</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], Loss: 0.7660771608352661, Accuracy: 45.75,  Test_loss: 1.2285920398712158, Test_accuracy: 55.95\n",
            "Epoch [1], Loss: 0.7466053366661072, Accuracy: 62.81,  Test_loss: 0.9519663627624512, Test_accuracy: 66.44\n",
            "Epoch [2], Loss: 1.199931263923645, Accuracy: 70.17,  Test_loss: 0.8615626026153564, Test_accuracy: 70.16\n",
            "Epoch [3], Loss: 1.124739170074463, Accuracy: 75.22,  Test_loss: 0.8328243703842163, Test_accuracy: 70.87\n",
            "Epoch [4], Loss: 0.7760188579559326, Accuracy: 78.84,  Test_loss: 0.8024488975524903, Test_accuracy: 73.56\n",
            "Epoch [5], Loss: 0.7488182783126831, Accuracy: 82.23,  Test_loss: 0.8036666326522827, Test_accuracy: 74.02\n",
            "Epoch [6], Loss: 0.5187238454818726, Accuracy: 85.23,  Test_loss: 0.8454585586547851, Test_accuracy: 73.1\n",
            "Epoch [7], Loss: 0.2754251956939697, Accuracy: 87.31,  Test_loss: 0.8719929852485657, Test_accuracy: 73.46\n",
            "Epoch [8], Loss: 0.2809068560600281, Accuracy: 89.74,  Test_loss: 1.0231557291984559, Test_accuracy: 72.31\n",
            "Epoch [9], Loss: 0.1009332686662674, Accuracy: 91.44,  Test_loss: 1.1827536433696746, Test_accuracy: 72.32\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHHASFVtApW3",
        "colab_type": "text"
      },
      "source": [
        "## He Init\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiiFdwKdoCOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "        torch.nn.init.kaiming_uniform_(self.conv1.weight, mode='fan_in', nonlinearity='relu')\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
        "        torch.nn.init.kaiming_uniform_(self.conv2.weight, mode='fan_in', nonlinearity='relu')\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
        "        torch.nn.init.kaiming_uniform_(self.conv3.weight, mode='fan_in', nonlinearity='relu')\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, 1)\n",
        "        torch.nn.init.kaiming_uniform_(self.conv4.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "        self.pool1 = torch.nn.MaxPool2d(2)\n",
        "        self.pool2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.fc1 = nn.Linear(1600, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Conv 1st Block\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y534xBF1m70M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db6jPryFDa7m",
        "colab_type": "code",
        "outputId": "ca47d437-5103-46c3-fa1d-e8978a0dd888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "net = Net().to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "wandb.init(project='wtinit')\n",
        "wandb.watch(net, log='all')\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(net, device, trainloader, optimizer, epoch, steps_per_epoch=50000//32)\n",
        "  test(net, device, testloader, classes)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ayush-thakur/wtinit\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/wtinit</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ayush-thakur/wtinit/runs/2a5qddz3\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/wtinit/runs/2a5qddz3</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], Loss: 0.8680363893508911, Accuracy: 53.15,  Test_loss: 0.9655896467208862, Test_accuracy: 65.97\n",
            "Epoch [1], Loss: 0.9842775464057922, Accuracy: 69.86,  Test_loss: 0.8211903447151184, Test_accuracy: 71.67\n",
            "Epoch [2], Loss: 0.7356349229812622, Accuracy: 75.92,  Test_loss: 0.7943427026748657, Test_accuracy: 73.04\n",
            "Epoch [3], Loss: 0.47701454162597656, Accuracy: 80.88,  Test_loss: 0.7719963906049728, Test_accuracy: 74.26\n",
            "Epoch [4], Loss: 0.5376359224319458, Accuracy: 85.06,  Test_loss: 0.8065440139770508, Test_accuracy: 74.54\n",
            "Epoch [5], Loss: 0.16438741981983185, Accuracy: 88.42,  Test_loss: 0.8578581342697144, Test_accuracy: 75.66\n",
            "Epoch [6], Loss: 0.1592894345521927, Accuracy: 91.03,  Test_loss: 0.9687001671791077, Test_accuracy: 74.76\n",
            "Epoch [7], Loss: 0.11241734027862549, Accuracy: 93.03,  Test_loss: 1.1693744165897368, Test_accuracy: 72.9\n",
            "Epoch [8], Loss: 0.027939707040786743, Accuracy: 94.07,  Test_loss: 1.2283352478027343, Test_accuracy: 72.83\n",
            "Epoch [9], Loss: 0.2554128170013428, Accuracy: 94.88,  Test_loss: 1.3051767216205596, Test_accuracy: 72.79\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZWWEjfgl_g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}